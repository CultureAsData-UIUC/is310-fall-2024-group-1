import pandas as pd
import logging
import csv
import os
import requests
import time

# Configure logging
logging.basicConfig(filename='clean_IS310_Data.log', level=logging.INFO,
                    format='%(asctime)s:%(levelname)s:%(message)s')

def standardize_gender(gender):
    if pd.isna(gender):
        return 'Unknown'
    gender = gender.replace(',', '/').replace(' ', '').upper()
    if gender in ['M', 'F', 'M/F']:
        return gender
    return 'Other'

def standardize_operability(status):
    if pd.isna(status):
        return 'Unknown'
    status = status.lower()
    if 'operable' in status and 'non-operable' not in status:
        return 'Operable'
    elif 'non-operable' in status:
        return 'Non-operable'
    elif 'partially operable' in status:
        return 'Partially Operable'
    else:
        return 'Unknown'

def clean_game_link(link):
    if isinstance(link, str):
        return link.strip()
    return link

def fetch_flashpoint_metadata(game_name):
    api_url = f"https://api.flashpointarchive.org/game?search={game_name}"
    try:
        response = requests.get(api_url)
        response.raise_for_status()
        data = response.json()
        if data:
            return data[0]  # Assuming the first result is the most relevant
        else:
            return None
    except requests.exceptions.RequestException as e:
        logging.error(f"API request failed for '{game_name}': {e}")
        return None

def extract_genre(metadata):
    if metadata and 'genre' in metadata:
        return metadata['genre']
    return 'Unknown'

def inspect_csv_with_csv_module():
    try:
        with open('IS310 Data.csv', encoding='utf-8-sig') as f:
            reader = csv.reader(f, delimiter=',', quotechar='"')
            for i, row in enumerate(reader):
                print(f"Row {i}: {row}")
                if i >= 4:  # Inspect first 5 rows
                    break
    except FileNotFoundError:
        print("File 'IS310 Data.csv' not found.")
    except Exception as e:
        print(f"Error reading CSV with csv module: {e}")

def detect_invisible_characters():
    try:
        with open('IS310 Data.csv', 'rb') as f:
            content = f.read()
            non_printable = [byte for byte in content if byte < 32 and byte not in (9, 10, 13)]
            if non_printable:
                print(f"Non-printable characters detected: {non_printable}")
            else:
                print("No non-printable characters detected.")
    except FileNotFoundError:
        print("File 'IS310 Data.csv' not found.")
    except Exception as e:
        print(f"Error reading CSV for invisible characters: {e}")

def main():
    csv_path = 'IS310 Data.csv'
    absolute_csv_path = os.path.abspath(csv_path)
    print(f"Reading CSV from: {absolute_csv_path}\n")

    # Inspect the CSV first
    print("Inspecting CSV with csv.reader:")
    inspect_csv_with_csv_module()

    # Detect invisible characters
    print("\nDetecting invisible characters in CSV:")
    detect_invisible_characters()

    try:
        df = pd.read_csv(
            csv_path,
            encoding='utf-8-sig',
            sep=',',
            quotechar='"',
            engine='python',
            on_bad_lines='skip'
        )
        logging.info("Loaded 'IS310 Data.csv' successfully.")
        print("\nColumns Detected:", df.columns.tolist())
    except FileNotFoundError:
        logging.error("File 'IS310 Data.csv' not found.")
        return
    except pd.errors.ParserError as e:
        logging.error(f"Pandas Parser Error: {e}")
        return
    except Exception as e:
        logging.error(f"Error loading CSV: {e}")
        return

    # Validate columns
    expected_columns = ['game_name', 'YOR', 'operability_status', 'developer', 'publisher', 'gender', 'no_of_skintones', 'game_link']
    missing_columns = [col for col in expected_columns if col not in df.columns]

    if missing_columns:
        print(f"Error: Missing columns in the CSV file: {missing_columns}")
        logging.error(f"Missing columns in the CSV file: {missing_columns}")
        return
    else:
        print("All expected columns are present.")
        logging.info("All expected columns are present.")

    # Standardize Column Names
    df.columns = [col.strip().upper().replace(' ', '_').replace('.', '') for col in df.columns]

    # Clean and standardize data
    df['DEVELOPER'] = df['DEVELOPER'].fillna('Unknown')
    df['PUBLISHER'] = df['PUBLISHER'].fillna('Unknown')
    df['GENDER'] = df['GENDER'].apply(standardize_gender)
    df['NO_OF_SKINTONES'] = pd.to_numeric(df['NO_OF_SKINTONES'], errors='coerce').fillna(0).astype(int)
    df['GAME_LINK'] = df['GAME_LINK'].apply(clean_game_link)
    df['OPERABILITY_STATUS'] = df['OPERABILITY_STATUS'].apply(standardize_operability)
    df['YOR'] = pd.to_numeric(df['YOR'], errors='coerce').fillna(0).astype(int)

    # Fetch metadata from Flashpoint API
    print("\nFetching metadata from Flashpoint API...")
    df['API_METADATA'] = df['GAME_NAME'].apply(fetch_flashpoint_metadata)
    df['GENRE'] = df['API_METADATA'].apply(extract_genre)

    # Remove duplicates
    before_dedup = len(df)
    df = df.drop_duplicates(subset=['GAME_NAME', 'YOR'])
    after_dedup = len(df)
    logging.info(f"Removed duplicates: {before_dedup - after_dedup} entries dropped.")

    # Reset index
    df.reset_index(drop=True, inplace=True)

    # Display cleaned data
    print("\nCleaned Data Info:")
    print(df.info())
    print("\nCleaned Data Sample:")
    print(df.head())

    # Save cleaned dataset with API metadata
    try:
        df.to_csv('cleaned_dress_up_games_with_api.csv', index=False)
        logging.info("Cleaned data saved to 'cleaned_dress_up_games_with_api.csv'.")
        print("\nCleaned data saved to 'cleaned_dress_up_games_with_api.csv'")
    except Exception as e:
        logging.error(f"Error saving cleaned CSV: {e}")

if __name__ == "__main__":
    main()
